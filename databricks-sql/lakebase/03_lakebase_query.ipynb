{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lakebase Data Querying & Analysis\n",
    "\n",
    "This notebook demonstrates how to query and analyze data from your Lakebase database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "from databricks.sdk import WorkspaceClient\n",
    "import uuid\n",
    "import logging\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "INSTANCE_NAME = \"rb-demo-lakebase\"\n",
    "PROFILE = \"az-demo\"\n",
    "USER_NAME = \"rohit.bhagwat@databricks.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Connected to instance: rb-demo-lakebase\n"
     ]
    }
   ],
   "source": [
    "# Get instance and generate credentials\n",
    "w = WorkspaceClient(profile=PROFILE)\n",
    "instance = w.database.get_database_instance(name=INSTANCE_NAME)\n",
    "cred = w.database.generate_database_credential(\n",
    "    request_id=str(uuid.uuid4()), \n",
    "    instance_names=[INSTANCE_NAME]\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Connected to instance: {instance.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Connected to PostgreSQL database\n"
     ]
    }
   ],
   "source": [
    "# Connect to PostgreSQL\n",
    "conn = psycopg2.connect(\n",
    "    host=instance.read_write_dns,\n",
    "    dbname=\"databricks_postgres\",\n",
    "    user=USER_NAME,\n",
    "    password=cred.token,\n",
    "    sslmode=\"require\"\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Connected to PostgreSQL database\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Found 5 coffee shops\n",
      "\n",
      "First 3 shops:\n",
      "  1. Brew & Bean Downtown - San Francisco, CA\n",
      "  2. Mocha Haven Central - New York, NY\n",
      "  3. Espresso Corner - Seattle, WA\n"
     ]
    }
   ],
   "source": [
    "# Get all coffee shops\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SELECT * FROM coffee_operations.coffee_shops\")\n",
    "    rows = cur.fetchall()\n",
    "    \n",
    "print(f\"üìä Found {len(rows)} coffee shops\")\n",
    "print(\"\\nFirst 3 shops:\")\n",
    "for i, row in enumerate(rows[:3]):\n",
    "    print(f\"  {i+1}. {row[1]} - {row[2]}, {row[3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geographic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåç Shops by Country:\n",
      "   United States: 3 shops, avg 35 seats\n",
      "   France: 1 shops, avg 50 seats\n",
      "   Japan: 1 shops, avg 35 seats\n"
     ]
    }
   ],
   "source": [
    "# Analyze shops by country\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"\"\"\n",
    "        SELECT country, COUNT(*) as shop_count, AVG(seating_capacity) as avg_capacity\n",
    "        FROM coffee_operations.coffee_shops\n",
    "        GROUP BY country\n",
    "        ORDER BY shop_count DESC\n",
    "    \"\"\")\n",
    "    \n",
    "    country_stats = cur.fetchall()\n",
    "    \n",
    "print(\"üåç Shops by Country:\")\n",
    "for country, count, avg_cap in country_stats:\n",
    "    print(f\"   {country}: {count} shops, avg {avg_cap:.0f} seats\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Premium vs Standard Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚≠ê Premium vs Standard Analysis:\n",
      "\n",
      "Premium Locations (3 shops):\n",
      "   Average capacity: 42.3 seats\n",
      "   Capacity range: 32 - 50 seats\n",
      "\n",
      "Standard Locations (2 shops):\n",
      "   Average capacity: 31.5 seats\n",
      "   Capacity range: 28 - 35 seats\n"
     ]
    }
   ],
   "source": [
    "# Compare premium vs standard locations\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"\"\"\n",
    "        SELECT \n",
    "            is_premium_location,\n",
    "            COUNT(*) as shop_count,\n",
    "            AVG(seating_capacity) as avg_capacity,\n",
    "            MIN(seating_capacity) as min_capacity,\n",
    "            MAX(seating_capacity) as max_capacity\n",
    "        FROM coffee_operations.coffee_shops\n",
    "        GROUP BY is_premium_location\n",
    "        ORDER BY is_premium_location DESC\n",
    "    \"\"\")\n",
    "    \n",
    "    premium_stats = cur.fetchall()\n",
    "    \n",
    "print(\"‚≠ê Premium vs Standard Analysis:\")\n",
    "for is_premium, count, avg_cap, min_cap, max_cap in premium_stats:\n",
    "    type_label = \"Premium\" if is_premium else \"Standard\"\n",
    "    print(f\"\\n{type_label} Locations ({count} shops):\")\n",
    "    print(f\"   Average capacity: {avg_cap:.1f} seats\")\n",
    "    print(f\"   Capacity range: {min_cap} - {max_cap} seats\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Zone Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üïê Shops by Time Zone:\n",
      "\n",
      "America/Los_Angeles (2 shops):\n",
      "   Brew & Bean Downtown, Espresso Corner\n",
      "\n",
      "America/New_York (1 shops):\n",
      "   Mocha Haven Central\n",
      "\n",
      "Asia/Tokyo (1 shops):\n",
      "   Tokyo Roast\n",
      "\n",
      "Europe/Paris (1 shops):\n",
      "   Caf√© Paris\n"
     ]
    }
   ],
   "source": [
    "# Analyze shops by time zone\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"\"\"\n",
    "        SELECT \n",
    "            time_zone,\n",
    "            COUNT(*) as shop_count,\n",
    "            STRING_AGG(shop_name, ', ' ORDER BY shop_name) as shop_names\n",
    "        FROM coffee_operations.coffee_shops\n",
    "        GROUP BY time_zone\n",
    "        ORDER BY shop_count DESC\n",
    "    \"\"\")\n",
    "    \n",
    "    tz_stats = cur.fetchall()\n",
    "    \n",
    "print(\"üïê Shops by Time Zone:\")\n",
    "for tz, count, names in tz_stats:\n",
    "    print(f\"\\n{tz} ({count} shops):\")\n",
    "    print(f\"   {names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data into Pandas for Advanced Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/70/x9xt8g1153qcq89qgj06ymcm0000gp/T/ipykernel_74654/1035384310.py:10: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Loaded 5 rows into DataFrame\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shop_id</th>\n",
       "      <th>shop_name</th>\n",
       "      <th>city</th>\n",
       "      <th>state_province</th>\n",
       "      <th>country</th>\n",
       "      <th>time_zone</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>seating_capacity</th>\n",
       "      <th>is_premium_location</th>\n",
       "      <th>is_active</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CS001</td>\n",
       "      <td>Brew &amp; Bean Downtown</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "      <td>United States</td>\n",
       "      <td>America/Los_Angeles</td>\n",
       "      <td>37.7749</td>\n",
       "      <td>-122.4194</td>\n",
       "      <td>45</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-08-15 20:29:11.132816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CS004</td>\n",
       "      <td>Caf√© Paris</td>\n",
       "      <td>Paris</td>\n",
       "      <td>√éle-de-France</td>\n",
       "      <td>France</td>\n",
       "      <td>Europe/Paris</td>\n",
       "      <td>48.8566</td>\n",
       "      <td>2.3522</td>\n",
       "      <td>50</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-08-15 21:00:33.721063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CS003</td>\n",
       "      <td>Espresso Corner</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "      <td>United States</td>\n",
       "      <td>America/Los_Angeles</td>\n",
       "      <td>47.6062</td>\n",
       "      <td>-122.3321</td>\n",
       "      <td>28</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-08-15 20:29:11.200018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CS002</td>\n",
       "      <td>Mocha Haven Central</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>United States</td>\n",
       "      <td>America/New_York</td>\n",
       "      <td>40.7128</td>\n",
       "      <td>-74.0060</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-08-15 20:29:11.168116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CS005</td>\n",
       "      <td>Tokyo Roast</td>\n",
       "      <td>Tokyo</td>\n",
       "      <td>Tokyo</td>\n",
       "      <td>Japan</td>\n",
       "      <td>Asia/Tokyo</td>\n",
       "      <td>35.6762</td>\n",
       "      <td>139.6503</td>\n",
       "      <td>35</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-08-15 21:00:33.757406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  shop_id             shop_name           city state_province        country  \\\n",
       "0   CS001  Brew & Bean Downtown  San Francisco             CA  United States   \n",
       "1   CS004            Caf√© Paris          Paris  √éle-de-France         France   \n",
       "2   CS003       Espresso Corner        Seattle             WA  United States   \n",
       "3   CS002   Mocha Haven Central       New York             NY  United States   \n",
       "4   CS005           Tokyo Roast          Tokyo          Tokyo          Japan   \n",
       "\n",
       "             time_zone  latitude  longitude  seating_capacity  \\\n",
       "0  America/Los_Angeles   37.7749  -122.4194                45   \n",
       "1         Europe/Paris   48.8566     2.3522                50   \n",
       "2  America/Los_Angeles   47.6062  -122.3321                28   \n",
       "3     America/New_York   40.7128   -74.0060                32   \n",
       "4           Asia/Tokyo   35.6762   139.6503                35   \n",
       "\n",
       "   is_premium_location  is_active                 created_at  \n",
       "0                 True       True 2025-08-15 20:29:11.132816  \n",
       "1                 True       True 2025-08-15 21:00:33.721063  \n",
       "2                False       True 2025-08-15 20:29:11.200018  \n",
       "3                 True       True 2025-08-15 20:29:11.168116  \n",
       "4                False       True 2025-08-15 21:00:33.757406  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load all data into pandas DataFrame\n",
    "query = \"\"\"\n",
    "    SELECT shop_id, shop_name, city, state_province, country, \n",
    "           time_zone, latitude, longitude, seating_capacity, \n",
    "           is_premium_location, is_active, created_at\n",
    "    FROM coffee_operations.coffee_shops\n",
    "    ORDER BY shop_name\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql_query(query, conn)\n",
    "print(f\"üìä Loaded {len(df)} rows into DataFrame\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà Summary Statistics:\n",
      "        latitude   longitude  seating_capacity                     created_at\n",
      "count   5.000000    5.000000          5.000000                              5\n",
      "mean   42.125340  -35.351000         38.000000  2025-08-15 20:41:44.195883776\n",
      "min    35.676200 -122.419400         28.000000     2025-08-15 20:29:11.132816\n",
      "25%    37.774900 -122.332100         32.000000  2025-08-15 20:29:11.168115968\n",
      "50%    40.712800  -74.006000         35.000000  2025-08-15 20:29:11.200017920\n",
      "75%    47.606200    2.352200         45.000000  2025-08-15 21:00:33.721062912\n",
      "max    48.856600  139.650300         50.000000     2025-08-15 21:00:33.757406\n",
      "std     5.870747  110.326576          9.192388                            NaN\n",
      "\n",
      "üåç Geographic Coverage:\n",
      "   Countries: 3\n",
      "   Cities: 5\n",
      "   Time Zones: 4\n"
     ]
    }
   ],
   "source": [
    "# Summary statistics\n",
    "print(\"üìà Summary Statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "print(\"\\nüåç Geographic Coverage:\")\n",
    "print(f\"   Countries: {df['country'].nunique()}\")\n",
    "print(f\"   Cities: {df['city'].nunique()}\")\n",
    "print(f\"   Time Zones: {df['time_zone'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Query session complete!\n"
     ]
    }
   ],
   "source": [
    "# Close connection\n",
    "conn.close()\n",
    "print(\"\\n‚úÖ Query session complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What You've Accomplished\n",
    "\n",
    "‚úÖ **Connected** to Lakebase PostgreSQL database  \n",
    "‚úÖ **Explored** coffee shop data across multiple countries  \n",
    "‚úÖ **Analyzed** premium vs standard location patterns  \n",
    "‚úÖ **Examined** geographic and time zone distributions  \n",
    "‚úÖ **Loaded** data into pandas for advanced analytics  \n",
    "\n",
    "This demonstrates how Lakebase provides both operational database capabilities and analytical querying power in one unified platform!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
